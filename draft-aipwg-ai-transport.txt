



AIP-WG                                                         O. Daichi
                                                                   FOALK
                                                         15 January 2025


                         AI Transport Protocol
                    draft-aipwg-ai-transport-latest

Abstract

   AIP is designed to provide a framework for seamless integration of
   AI-powered communication systems, ensuring that AI agents can
   interact effectively with diverse web resources, facilitate efficient
   data exchanges, and ensure both factual accuracy and security within
   transportation protocols.  This document outlines the key principles,
   concepts, and specifications for the AI Transport Protocol (AIP).

Discussion Venues

   This note is to be removed before publishing as an RFC.

   Source for this draft and an issue tracker can be found at
   https://github.com/aip-wg/ai-transport.

Table of Contents

   1.  Introduction
     1.1.  Motivation
       1.1.1.  Leveraging AI
       1.1.2.  Factual Integrity
       1.1.3.  Reachability
       1.1.4.  Accessibility
       1.1.5.  Traceability
       1.1.6.  Latency
     1.2.  Purpose
       1.2.1.  Large Integrated Resource
       1.2.2.  Educational Use of AI
     1.3.  Scope
     1.4.  Terms and Definitions
   2.  Concepts
     2.1.  Media over QUIC's Concepts
       2.1.1.  Transport
       2.1.2.  Session
       2.1.3.  Track
       2.1.4.  Group
       2.1.5.  Announcement
       2.1.6.  Subscription
       2.1.7.  Fetch Request
       2.1.8.  Relay
     2.2.  Model Content Protocol Concepts
       2.2.1.  MCP Server
       2.2.2.  MCP Client
       2.2.3.  Resources
       2.2.4.  Tools
       2.2.5.  Prompts
       2.2.6.  Request-Response
       2.2.7.  Notification
     2.3.  Verification Levels
       2.3.1.  Level 3: Official Pronouncements
       2.3.2.  Level 2: Corporate and Industry Sources
       2.3.3.  Level 1: Individual Comments
       2.3.4.  Level 0: Unverified Content
     2.4.  Protocol Architecture
   3.  MCP Endpoints Interactions
     3.1.  MCP Messages
       3.1.1.  REQUEST Structure
       3.1.2.  RESULT Structure
       3.1.3.  ERROR Structure
       3.1.4.  RESOURCE
       3.1.5.  TOOL
       3.1.6.  PROMPT Structure
       3.1.7.  Concept Mapping
     3.2.  Transport Mechanisms
       3.2.1.  Set up
       3.2.2.  Announce
       3.2.3.  Subscribe
       3.2.4.  Fetch
       3.2.5.  Terminate
   4.  Implementation Guidelines
     4.1.  Best Practices
     4.2.  Performance Considerations
   5.  IANA Considerations
   6.  Security Considerations
   7.  References
     7.1.  Normative References
     7.2.  Informative References
   8.  Acknowledgments
   Author's Address

1.  Introduction

1.1.  Motivation

1.1.1.  Leveraging AI

   AI Agents have the potential to revolutionize various domains by
   automating and enhancing data exchange, decision-making, and
   interactions with external systems.  However, their widespread
   adoption depends on ensuring that they are equipped with accurate,
   accessible, and verifiable data.  This protocol aims to provide the
   framework that AI agents can use to interact with data sources
   effectively while ensuring minimal risk of misinformation and
   guaranteeing that AI-driven outputs are reliable.

1.1.2.  Factual Integrity

   To facilitate the effective use of AI-generated content by humans, it
   is crucial that the generated information remains highly faithful to
   factual accuracy.  At a minimum, AI agents must ensure that
   referenced information is neither distorted nor misrepresented, and
   that the generated content maintains logical consistency.
   Furthermore, factual integrity is essential for building trust in AI-
   generated outputs.  When AI systems produce content that aligns with
   verifiable sources without introducing misinformation, users can rely
   on them with greater confidence.  Maintaining factual integrity also
   reduces the risk of spreading inaccuracies, thereby enhancing the
   reliability and usability of AI-generated content across various
   domains.

1.1.3.  Reachability

   AI agents are required to generate outputs based on various inputs,
   including resources that may not be explicitly specified.  Therefore,
   it is essential that all necessary resources are accessible to AI
   agents and that they are aware of where to obtain specific
   information.  This ensures that AI agents can function effectively,
   without limitations, in retrieving and processing the data required
   for accurate outputs.

1.1.4.  Accessibility

   Web resources may restrict AI agents from scraping content,
   particularly for critical components such as advertisements or other
   important sections of a site.  This restriction could result in the
   inaccessibility of essential data, limiting the AI's ability to
   function optimally.  The protocol addresses these challenges by
   outlining strategies for AI agents to respect data access rules while
   still ensuring valuable resources are reachable when needed.

1.1.5.  Traceability

   To ensure the reliability and transparency of AI-generated outputs,
   it is necessary to establish traceability mechanisms.  These
   mechanisms allow for tracking the sources and reasoning behind the
   data used by AI agents in generating content.  This will help verify
   the quality of the data and provide accountability for the outputs
   generated, which is crucial in sensitive contexts such as legal,
   medical, and financial applications.

1.1.6.  Latency

   Reducing latency in communication between AI agents and data sources
   is vital for ensuring responsive and real-time interactions.  The
   protocol establishes guidelines for minimizing latency and ensuring
   that AI agents can efficiently process and respond to data requests
   in a timely manner.  Optimized transport mechanisms will contribute
   to lowering delays and improving the overall user experience.

1.2.  Purpose

1.2.1.  Large Integrated Resource

   Establish a robust network of Model Content Protocol (MCP) servers to
   facilitate seamless communication between AI agents and various
   external data sources.  This network will serve as the backbone for
   enabling efficient data retrieval, processing, and integration into
   AI systems, ensuring smooth and consistent interactions across
   different platforms.

1.2.2.  Educational Use of AI

   Promote the greater adoption of AI in educational contexts, enhancing
   learning methods through AI agents that interact with students,
   provide personalized feedback, and facilitate dynamic learning
   experiences.  AI agents can help create customized educational
   environments, where students’ progress is tracked and tailored
   learning paths are provided based on their individual needs.

1.3.  Scope

   The scope of this document includes the design and specification of a
   transport protocol that enables AI agents to interact with web
   resources and external data sources effectively.  This protocol
   ensures that AI agents maintain factual integrity, adhere to access
   policies, and minimize latency, all while supporting educational and
   other use cases.  It covers the communication mechanisms, data
   formats, security considerations, and best practices for implementing
   and utilizing this protocol.

1.4.  Terms and Definitions

   *  *AI Agent*: A system that uses artificial intelligence to process
      data, generate content, or interact with users and other systems.

   *  *MCP Server*: A server that implements the Model Content Protocol
      to facilitate the integration of external data sources with AI
      applications.

   *  *Web Resource*: A source of data available on the web, which may
      include web pages, databases, APIs, or other online content.

   *  *Transport Protocol*: A protocol designed to facilitate the
      exchange of data between systems, ensuring efficient and secure
      communication.

   *  *Factual Integrity*: The quality of information being true,
      accurate, and free from distortion or misrepresentation.

2.  Concepts

2.1.  Media over QUIC's Concepts

   Media over QUIC (MOQ) is a live media protocol powered by QUIC

2.1.1.  Transport

   In this protocol, use the MOQTransport protocol for transport,
   ensuring the secure and efficient transmission of data between AI
   agents and external systems.

2.1.2.  Session

   The session of the MOQ concept.  The MOQ session provides a framework
   for managing ongoing interactions between AI agents and external data
   sources, ensuring that context and state are preserved during the
   communication process.

2.1.3.  Track

   A single resource delivered as a "track" within the MOQ system.  A
   track may refer to any distinct data set, file, or content that is
   used in the protocol’s operations.

2.1.4.  Group

   A group is a set of data sent in a single QUIC stream.

2.1.5.  Announcement

   The MOQ's Announcement.  It indicates where endpoints can find
   resources such as MCP server.

2.1.6.  Subscription

   The MOQ's Subscription.  A single subscription is a single resource.

2.1.7.  Fetch Request

   The MOQ's Fetch Request.  Endpoints send request to the other as the
   MOQ's Fetch Request.  Thus request and responce will be negotiated on
   a single QUIC stream.

2.1.8.  Relay

   The MOQ relay is a component that facilitates the transfer of data
   between AI agents and external resources, ensuring that communication
   is efficient and reliable.

2.2.  Model Content Protocol Concepts

   Model Content Protocol (MCP) is an open protocol designed to enable
   seamless integration between large language model (LLM) applications
   and external data sources.  It facilitates secure data exchanges,
   improving the accessibility and utility of AI systems.

2.2.1.  MCP Server

   MCP servers provides information from resources to MCP clients

2.2.2.  MCP Client

   MCP clients comminucate with MCP servers and accesses to modified
   resources through the server.

2.2.3.  Resources

   The Resources of the MCP concept.  Every resources maps to a single
   track.

   *  *Remote Resource*: A resource that is served from a remote server,
      such as an API response.

   *  *Local Resource*: A resource that is located within a local
      environment, such as a database or file system, providing content
      that is directiory accessible by the AI agent.

2.2.4.  Tools

   The Tools of the MCP concept.  Functions that can be called by the
   LLM

2.2.5.  Prompts

   The Prompts of the MCP concept.  Pre-written templates that help
   users accomplish specific tasks

2.2.6.  Request-Response

   An endpoint sends a REQUEST message to another endpoint.  The
   receiving endpoint verifies if it has a method that matches the
   Method Name and processes the Parameters.  The endpoint that received
   the request responds by sending a RESULT message.

2.2.7.  Notification

   An endpoint informs other endpoints about the methods it supports by
   sending a NOTIFICATION message.

2.3.  Verification Levels

   Verification levels indicate the reliability of the generated data.

2.3.1.  Level 3: Official Pronouncements

   Content generated from authoritative sources, such as government
   reports or officially published information, which carries a high
   level of reliability.

2.3.2.  Level 2: Corporate and Industry Sources

   Content generated from corporate websites, industry reports, and
   professional publications.  These sources are generally reliable but
   should still be verified.

2.3.3.  Level 1: Individual Comments

   Content generated from individual comments on the web, such as social
   media posts, blog entries, and forum discussions.  These sources vary
   in reliability and should be verified for accuracy.

2.3.4.  Level 0: Unverified Content

   Content from anonymous sources or user-generated content that has not
   been verified.  This level carries the lowest reliability.

2.4.  Protocol Architecture

3.  MCP Endpoints Interactions

3.1.  MCP Messages

   MCP messages are JSON-RPC 2.0 style.

3.1.1.  REQUEST Structure

   REQUEST {
     id: Request ID (i),
     method: Method Name (b),
     parameters: [
       {
         id: Parameter ID (i),
         value: Parameter Value (b),
       }
     ]
   }

3.1.2.  RESULT Structure

   RESULT {
     id: Request ID (i),
     [key: Responce Key (b)]: Responce Value (b),
   }

3.1.3.  ERROR Structure

   ERROR {
     code: Error Code (i),
     reason: Reason (b),
     data: Data (b),
   }

   ### NOTIFICATION Structure
   ~~~text
   NOTIFICATION {
     id: Notification ID (i),
     method: Method Name (b),
     arguments: [
       {
         id: Argument ID (i),
         type: Argument Type (i),
       }
     ]
   }

3.1.4.  RESOURCE

3.1.5.  TOOL

3.1.6.  PROMPT Structure

   PROMPT {
     name: Prompt Name (b),
     parameters?: [
       {
         id: Parameter ID (i),
         name: Parameter Name (b),
         required: Required (i),
       }...
     ]
   }

3.1.7.  Concept Mapping

   *  "prompts/list" endpoint -> A Track named "prompts"

3.2.  Transport Mechanisms

3.2.1.  Set up

   A session is established by a client connecting to a server using the
   MOQ (Media over QUIC) protocol.  During the setup phase, the client
   initiates a connection request to the server.  Any additional
   information required for the session, such as authentication tokens
   or configuration parameters, should be included as extensions to the
   MOQ setup messages.  This ensures that both the client and server
   have all necessary information to establish a secure and efficient
   communication channel.

3.2.2.  Announce

   Endpoints can discover available resources through MOQ announce
   negotiation.  This process begins with a subscriber indicating to a
   publisher the specific resources they are interested in.  The
   publisher then responds with an announcement detailing the available
   resources.  This negotiation allows for dynamic resource discovery
   and ensures that subscribers are aware of the resources they can
   access.  The server's announcement includes metadata about the
   resources, such as their type, availability, and any access
   restrictions.

3.2.3.  Subscribe

   Reserved Tracks

3.2.4.  Fetch

3.2.5.  Terminate

4.  Implementation Guidelines

4.1.  Best Practices

4.2.  Performance Considerations

5.  IANA Considerations

6.  Security Considerations

7.  References

7.1.  Normative References

7.2.  Informative References

8.  Acknowledgments

Author's Address

   Okutani Daichi
   FOALK
   Email: daichi1616.kytuniv@gmail.com
